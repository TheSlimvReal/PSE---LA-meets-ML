\documentclass[parskip=full]{scrartcl}
\usepackage[utf8]{inputenc} % use utf8 file encoding for TeX sources
\usepackage[T1]{fontenc}    % avoid garbled Unicode text in pdf
\usepackage[german, english]{babel}  % german hyphenation, quotes, etc
\usepackage{graphicx}       % provides commands for including figures
\usepackage{rotating}
\usepackage{amsmath}
\usepackage{pdfpages}
\graphicspath{ {images/} }
\usepackage{hyperref}       % detailed hyperlink/pdf configuration
\hypersetup{                % ‘texdoc hyperref‘ for options
pdftitle={PSE : LAMeetsML},%
bookmarks=true,%
}
\usepackage{csquotes}       % provides \enquote{} macro for "quotes"
\usepackage[nonumberlist, acronym]{glossaries} % provides glossary commands
\usepackage{enumitem}
\usepackage{lscape}
\usepackage{caption}
%\usepackage{placeins}
\usepackage[section]{placeins}

%\documentclass[12pt, oneside]{book}
\usepackage{wrapfig}
\usepackage{epstopdf}
\usepackage{caption, subcaption}



\makenoidxglossaries
%
%%Glossary
%

\newglossaryentry{algorithm}
{
	name=algorithm,
	plural=algorithms,
	description={In mathematics and computer science, an algorithm is an unambiguous specification of how to solve a class of problems. 
	Algorithms can perform calculation, data processing and automated reasoning tasks}
}

\newglossaryentry{classify module}
{
	name=classifier,
	plural= classifiers,
	description={The classifier is the last and main module in the program. 
	It is able to determine the fastest \gls{preconditioner}/\gls{iterative solver} combination for a given sparse linear system. 
	It uses the \gls{neural network} trained by the \gls{training module}}
}

\newglossaryentry{collector}
{
	name=collector,
	plural=collector,
	description={The collector is the first module in the program. 
	Responsible for generating artificial matrices and collection preexisting matrices from the suite sparse matrix collection}
}

\newglossaryentry{command-line interface}
{
	name=command-line interface,
	plural=command-lines interface,
	description={A command-line interface is a means of interacting with a computer program where the user (or client) issues commands to the program in the form of successive lines of text (command lines).
	A program which handles the interface is called a command language interpreter}
}

\newglossaryentry{Ginkgo}
{
	name=Ginkgo,
	plural=Ginkgo,
	description={Ginkgo is a high-performance linear algebra library for manycore systems, with a focus on sparse solution of linear systems}
}

\newglossaryentry{GPU}
{
	name=GPU,
	plural=GPUs,
	description={A GPU is a graphic processing unit which has specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device}
}

\newglossaryentry{grayscale sparsity pattern image}
{
	name=grayscale sparsity pattern image,
	plural=grayscale sparsity pattern images,
	description={Grayscale sparsity pattern image is an image, displaying the zero and nonzero areas of a matrix, by covering the zero areas white and all other areas by a shade of gray, depending on the value}
}

\newglossaryentry{iterative solver}
{
	name=iterative solver,
	plural=iterative solvers,
	description={In computational mathematics, an iterative solver does a mathematical procedure that uses an initial guess to generate a sequence of improving approximate solutions for a class of problems, in which the n-th approximation is derived from the previous ones}
}

\newglossaryentry{Keras}
{
	name=Keras,
	plural=Keras,
	description={Keras is an open source deep learning library written in Python}
}

\newglossaryentry{C++}
{
	name=C++,
	plural=C++,
	description={C++ is a sophisticated, efficient and a general-purpose programming language based on C}
}

\newglossaryentry{labeling module}
{
	name=labeling module,
	plural=labeling modules,
	description={The labeling module is the second module in the program. Responsible for executing a given set of matrices with all the \gls{preconditioner}/\gls{iterative solver}s combination specified. 
	It will furthermore label each matrix with the fastest combination}
}

\newglossaryentry{Linux}
{
	name=Linux,
	plural=Linux,
	description={Linux is an open-source software operating systems}
}

\newglossaryentry{neural network}
{
	name=neural network,
	plural=neural networks,
	description={The neural network itself is not an \gls{algorithm}, but rather a framework for many different machine learning \glspl{algorithm} to work together and process complex data inputs. 
	Such systems "learn" to perform tasks by considering examples, generally without being programmed with any task-specific rules}
}

\newglossaryentry{preconditioner}
{
	name=preconditioner,
	plural=preconditioners,
	description={In mathematics, preconditioning is the application of a transformation, that conditions a given problem into a form that is more suitable for numerical solving methods}
}

\newglossaryentry{Pytest}
{
	name=Pytest,
	plural=Pytests,
	description={Pytest is an alternative, more python fitting way of writing tests}
}

\newglossaryentry{Python}
{
	name=Python,
	plural=Python,
	description={Python is an interpreted high-level programming language for general-purpose programming}
}

\newglossaryentry{ResNet}
{
	name=resNet,
	plural=resNet,
	description={A deep residual network (deep ResNet) is a type of specialized neural network that helps to handle more sophisticated deep learning tasks and models}
}

\newglossaryentry{ssget}
{
	name=Ssget,
	plural=Ssget,
	description={Ssget is a command line tool for downloading matrices from the Suite Sparse Matrix Collection}
}

\newglossaryentry{Suite Sparse}
{
	name=Suite Sparse,
	plural=Suite Sparse,
	description={Suite Sparse is a suite of sparse matrix algorithms and Java interface to the Suite Sparse Matrix Collection}
}

\newglossaryentry{training module}
{
	name=training module,
	plural=training modules,
	description={The training module is the third module in the program. 
	Responsible for training a deep neural network with the set of matrices and labels given by the \gls{labeling module}}
}

\newglossaryentry{Windows}
{
	name=Windows,
	plural=Windows,
	description={Microsoft Windows is a group of several graphical operating system families, all of which are developed, marketed, and sold by Microsoft}
}


\newglossaryentry{gaussian noise}
{
	name=gaussian noise,
	plural=gaussian noises,
	description={The gaussian noise is statistical noise having a probability density function equal to that of the normal distribution, which is also known as the Gaussian distribution. 
	In other words, the values that the noise can take on are Gaussian-distributed}
}

\newglossaryentry{ctypes}
{
	name=ctype,
	plural=ctypes,
	description={ctypes is a foreign function library for Python}
}

\newglossaryentry{pointer}
{
	name=pointer,
	plural=pointers,
	description={a pointer is a programming language object that stores the memory address of another value located in computer memory}
}

\newglossaryentry{Pycharm}
{
	name=Pycharm,
	plural=Pycharm,
	description={PyCharm is an integrated development environment used in computer programming, specifically for the Python language}
}

\newglossaryentry{remote interpreter}
{
	name=remote interpreter,
	plural=remote interpreter,
	description={the code gets copied to a server where it will be compiled and run}
}

\newglossaryentry{CodeClimate}
{
	name= codeclimate,
	plural= codeclimate,
	description={Code Climate is an open, extensible platform for ensuring code health that analyzes trillions of lines of code per week.}
}

\newglossaryentry{.mat file}
{
	name= .mat file,
	plural=.mat files,
	description={.mat files contain MATLAB formatted data, and data can be loaded from or written to these files using the functions load and save, respectively.}
}

\newglossaryentry{LaTex}
{
	name=LaTex,
	plural=LaTex,
	description={LaTeX is a high-quality typesetting system; it includes features designed for the production of technical and scientific documentation. 
	LaTeX is the de facto standard for the communication and publication of scientific documents. }
}

\newglossaryentry{GIT}
{
	name=GIT,
	plural=GIT,
	description={Git is a distributed version-control system for tracking changes in source code during software development. 
	It is designed for coordinating work among programmers, but it can be used to track changes in any set of files.}
}

\newglossaryentry{GitHub}
{
	name=GitHub,
	plural=GitHub,
	description={GitHub Inc. is a web-based hosting service for version control using Git. 
	It is mostly used for computer code. 
	It offers all of the distributed version control and source code management functionality of Git as well as adding its own features. }
}

\newglossaryentry{ShareLaTeX}
{
	name=ShareLaTeX,
	plural=ShareLaTeX,
	description={ShareLaTeX is an online LaTeX editor that allows real-time collaboration and online compiling of projects to PDF format. In comparison to other LaTeX editors, ShareLaTeX is a server-based application, which is accessed through a web browser. }
}

\newglossaryentry{Slack}
{
	name=Slack,
	plural=Slack,
	description={Slack is an American cloud-based set of proprietary team collaboration tools and services, founded by Stewart Butterfield.}
}

\newglossaryentry{Travis}
{
	name=Travis,
	plural=Travis,
	description={Travis CI is a hosted, distributed continuous integration service used to build and test software projects hosted at GitHub. 
	Open source projects may be tested at no charge via travis-ci.org. 
	Private projects may be tested at travis-ci.com on a fee basis.}
}

\newglossaryentry{PEP8}
{
	name=PEP8,
	plural=PEP8,
	description={PEP 8 is Python's style guide. 
	It's a set of rules for how to format your Python code to maximize its readability. 
	Writing code to a specification helps to make large code bases, with lots of writers, more uniform and predictable, too.
	PEP is actually an acronym that stands for Python Enhancement Proposal.}
}

\newglossaryentry{cuda}
{
	name=cuda,
	plural=cuda,
	description={CUDA is a parallel computing platform and programming model invented by NVIDIA. 
	It enables dramatic increases in computing performance by harnessing the power of the graphics processing unit and it is used by Ginkgo}
}

\newglossaryentry{SSGet}
{
	name=SSGet,
	plural=SSGet,
	description={SSGet is a tool used for downloading matrices from Suite Sparse}
}
\begin{document}

\begin{titlepage}
\centering
{\scshape\LARGE Karlsruher Institut für Technologie\par}
\vspace{1cm}
{\scshape\Large Implementation Document (FSD)\par}
\vspace{1.5cm}
{\huge\bfseries Numerical Linear Algebra meets Machine Learning \par}
\vspace {2cm}

{\Large\itshape Fabian Koffer\par}
{\Large\itshape Simon Hanselmann\par}
{\Large\itshape Yannick Funk\par}
{\Large\itshape Dennis Leon Gr\"{o}tzinger\par}
{\Large\itshape Anna Katharina Ricker\par}

\vfill
Supervisors\par
Hartwig Anzt
Markus G\"{o}tz

\vfill
{\large\today\par}
\end{titlepage}

\tableofcontents
\newpage


\section{Introduction}
Goal was the delivery of a consistent software stack that allows for employing \glspl{neural network} for the linear system. 
The ecosystem should allow to train a \gls{neural network} on selecting a suitable \gls{iterative solver} depending on the linear system characteristics.

Since we were dealing with a big \gls{Python} project for the first time and we've never heard of \gls{Ginkgo} before, getting into program environment was the first challenge.
It turned out that our design was very good and we hardly had to make any changes.

Overall, our project now consists of around 1500 lines of \gls{Python} code and around 200 lines of \gls{C++} code.


\section{Changes on the Design}

\begin{figure}[!hbt]
    \centering
    \begin{subfigure}[b]{0.9\linewidth} 
        \centering
        \includegraphics[width=\textwidth]{../Big_classdiagram/Command_Changes.jpg}
        \caption{Changes in the command parsing module}
        \label{Changes in the command parsing module}
    \end{subfigure}
    \\
    \begin{subfigure}[b]{0.9\linewidth}
        \centering
        \includegraphics[width=\textwidth]{../Big_classdiagram/HelpClass_Changes.jpg}
        \caption{Changes in the Help classes module}
        \label{Changes in the Help classes module}
    \end{subfigure}
    \caption{Changes in the design}

\end{figure}

\begin{itemize}

\item We didn't implemented a matrix class, because we realized it is not useful to handle every matrix on its own. 
Instead we decided to handle it in numpy arrays.

\item We changed the command interface to an abstract class to reduce redundancy of the code.

\item We decided to let out the possibility to select a density, because we couldn't guarantee that the fetched and cut matrices from \gls{Suite Sparse} have the wanted density.

\item We added a help command, so the user is able to get an overview which commands can be executed.

\item We added a \gls{ssget} command so the user is able to update the file, where all the matrices ID's are listed.
When the \gls{Suite Sparse} collection is extended the list can be updated to include the new matrices. 

\item We renamed the Validator class to RegularityCalculator
\end{itemize}


\section{The Requirements}
\subsection{Following Requirements are accomplished}

\begin{itemize}
\item A software that supports the described work-flow design including the embedding of external components.

\item The software must be usable via a \gls{command-line interface} (CLI).

\item A data exchange format design that allows to store matrices and annotate them with 
additional meta-data, including labels.

\item An extensible design for multiple entities that are able to generate matrices in the proposed exchange format.

\item A dataset of at least 500 matrices in the envisioned data format and generated by the above two entities. 
There smallest share of matrices of a given entity must be no less than 30\% of the total number of contained matrices.

\item An extensible design that allows to solve the matrices using a configurable set of \gls{iterative solver} algorithms using a newly developed binding to the \gls{Ginkgo} linear algebra library.

\item A readily implemented and trained \gls{neural network} of the \gls{ResNet} architecture. 
It must be able to predict for a given matrix (in arbitrary format), which of the \gls{iterative solver} algorithms is the most suitable.

\item An entity that allows to store and load the trained \gls{neural network}.

\item The software must include entities for training and re-training a \gls{neural network} from scratch, respectively from a previously stored state.

\item The software must be able to show the predicted \gls{algorithm} and its associated suitability probability on the standard output.

\item Realization of a sustainable and quality-assured software development process. 
This includes a software design document, in-code documentation, unit testing and a continuous integration (CI).

\end{itemize}
Following optional requirements are accomplished:
\begin{itemize}
\item The software must be able to utilize GPU accelerators for the training and prediction capabilities of the neural network.
\end{itemize}


\subsection{Following Requirements were accomplished as far as possible}
\begin{itemize}

\item All mandatory requirements were as far as possible accomplished despite the cross-platformed compatibility is not fully given. 
This was not possible, because some used entities (\gls{ssget}, \gls{Ginkgo}) where not \gls{Windows} compatible.

\item Compared to the specification sheet there is just the possibility to fetch and cut \gls{Suite Sparse} matrices yet.
As we figured out our design we realized that generating random matrices is not that easy with our knowing.
So as already realized in the design document, because it is very rare to have same sized matrices from \gls{Suite Sparse}, it was not necessary to just fetch \gls{Suite Sparse} matrices in one size. 
Instead we just implemented a generator that fetches and cuts \gls{Suite Sparse} matrices.

\item We decided to let out the possibility to select a density as explained in the changes of design

\end{itemize}
Following optional requirements were accomplished as far as possible
\begin{itemize}
\item The system just supports four instead of five iterative solver \glspl{algorithm}.
One solver was not working properly so for now we decided just to use the four working solver \glspl{algorithm}.

\end{itemize}


\subsection{Following optional Requirements were not accomplished}
\begin{itemize}
\item A web interface to the software that is able to select a single, a set or all matrices of an uploadable file for prediction by the \gls{neural network}. 
The web interface may also be able to visualize the contained matrices, annotated labels as well as prediction results.

\item Scalability of the workflow including matrix generation, training, prediction in that multiple processors may be used in parallel.

\end{itemize}


\section{Tests}

\subsection{Controller}
\subsubsection{test\_command\_parser}
This test checks the functionality of the command parser.
It has following tests:

\begin{itemize}

\item test\_valid\_input\_returns\_command

\item test\_valid\_input\_with\_arguments

\item test\_valid\_input\_with\_flag

\item test\_invalid\_mode\_throws\_exception

\item test\_valid\_collector\_input

\item test\_valid\_label\_mode

\item test\_fails\_when\_entering\_invalid\_module

\item test\_quit\_with\_arguments\_throws\_error

\item test\_collector\_with\_missing\_optional\_args\_adds\_default

\item test\_classify\_command\_with\_missing\_optional\_arg\_adds\_default

\end{itemize}

\subsubsection{test\_controller}
This test checks the functionality of the controller.
It has following tests:

\begin{itemize}

\item test\_controller\_with\_two\_iterations

\item test\_invalid\_input\_calls\_print\_error

\item test\_help\_flag\_print

\item test\_ssget\_update\_command\_calls\_new\_search

\end{itemize}

\subsection{model}
\subsubsection{test collector}
This test checks the functionality of the collector.
It has following tests:

\begin{itemize}

\item test\_collect

\end{itemize}

\subsection{shared}
\subsubsection{test configurations}
This test checks the functionality of the loading of the configurations.
It has following tests:

\begin{itemize}

\item test\_loading\_config\_values\_works

\item test\_loading\_config\_has\_right\_value

\end{itemize}

\subsection{view}
\subsubsection{test cli output service}
This test checks the functionality of the view.
It has following tests:

\begin{itemize}

\item test\_create\_observable\_to\_print\_three\_values

\end{itemize}

\section{Delays and Problems}
\subsection{Labeling module}
Our main problem was with the \gls{Ginkgo}. 
It was barely documented what made working with it very hard and caused a delay in our implementation plan. 

First we had to find out, how to use \gls{Ginkgo} and because there was no good documentation we just had examples of the repository to work with.

The next difficulty was to integrate \gls{C++}.
We didn't managed to find that out by our own, but with \gls{ctypes} and the help of Markus (he wrote us a tutorial) we could integrate \gls{C++}.

After that we needed to figure out how to transfer the data to \gls{C++}.
With \gls{pointer} in \gls{Python}, csr matrix format and more examples from \gls{Ginkgo} repository we also solved this Problem.

The following step was to find out how the server we use works so we can find out how to use \gls{Pycharm} on the server.
This we got to work with a \gls{remote interpreter}.

The high resolution clock function in \gls{C++} solved our next problem: the determination of the time the solvers need.

The last problem was, that the \gls{cuda} server wasn't working, because there was a bug in \gls{Ginkgo} on the Server.
So Markus has to help us again to fix that.

After that we just had to clean up the methods to let them pass the \gls{CodeClimate} tests.
Therefore we tried to outsource functions, especially our function that chooses which solver is to be selected.
That we tried this by mapping with \glspl{pointer}.
Because here the return type was not possible, so it didn't work, we finally handled the problems with templates, how Markus showed us.


\subsection{MVC}
The Basic structure for MVC was very easy to implement.
Through preliminary work in the implementation phase, it was very easy to build the basic structure 
However, there were some problems with integration with real modules later.
\subsection{Training module}
The problem with the \gls{labeling module} caused a delay in the implementation of the \gls{training module} and the \gls{classify module}.
testing the training / \gls{classify module}, was difficult, because the data from \gls{labeling module} were needed.

\subsection{Collector}
As we started implementing the \gls{collector} our first barrier was \gls{ssget}. 
Finding out how to download matrices was not the problem.
But every matrix itself was saved on different places in the different \glspl{.mat file}, so the only way to find the matrices was with implementing a method that finds the file type every matrix is saved in.

\section{Lessons learned}
First of all we thought the machine learning part of this software will be the hardest part.
But it turned out to be on of the easiest.
Instead of that \gls{Ginkgo} was the main problem.
For other projects it probably will be easier to use of a better documented library.
On the other hand did we need this specific \gls{GPU} accelerated solvers, so there probably would have been no better or similar solution.

It was also a lesson that it is not worth to spend much time in data
preprocessing, because \gls{Keras} offers many possibilities.

Merging the \gls{LaTex} documents was a problem, because we didn't had a good \gls{LaTex}-Editor that supports versioning tools like \gls{GIT}.
Also we sometimes didn't start a new line for each sentence which resulted in bad readability on the pull requests on \gls{GitHub}.
In future it would be better to use for example \gls{ShareLaTeX} that allows you to edit the same project simultaneously.

\section{Statistics}
 
\begin{itemize}

\item lines of \gls{Python} code: 1500

\item lines of \gls{C++} code: 200

\item commits: 200

\item test coverage: 80\%

\end{itemize}
\subsection{Work Splitting}
\begin{itemize}

\item \Gls{collector}: Yannick and Anna

\item \Gls{labeling module}: Fabian and Dennis

\item \Gls{training module}: Yannick

\item \Gls{classify module}: Yannick

\item Command parsing module: Simon

\item Output service module: Simon

\item Help classes: Yannick

\item Continuous Integration/Code Reports: Simon

\item Implementation report: Anna

\end{itemize}


\section{Development model}
\subsection{Communication in the team}
%How was the communication in the team?
For talking about the progress and following steps the whole team met one to two times a week and another time with the tutor.
Dennis and Fabian worked on the \gls{labeling module} together while Yannick and Anna implemented the \gls{collector}.
Simon did the command parsing module and the output service module.
As soon as the \gls{labeling module} worked, Yannick implemented the \gls{training module} and the \gls{classify module}.
\subsection{Git}
For the previous steps, we already set up a \gls{GitHub} project where we all committed our work on.
Merging on the master branch was restricted from the beginning on.
If you think your changes are ready to be pushed to the master, you need to push your feature branch that is up-to-date with the master branch.
On \gls{GitHub} you can then create a pull request for this feature branch.
This will create a notification on \gls{Slack}.
Now one of the colleagues needs to review the pull request together with all the changes that happened to the code.
He can either suggest some changes or, if he thinks everything is alright, approve the changes.
For the implementation phase we also added two automatic checks that will run on all pull requests.
The first one is a CI-Tool which runs all tests.
If this test fails, the branch can't be merged into the master.
The other one is a code checking tool, which checks complexity and readability of the code.
This test is optional, but we still tried to keep this test passing.

\subsection{Continuous Integration}
For continuous integration we decided on \gls{Travis}-CI. 
That is because it works very well with GitHub and also offers free workers for the build process.
The build consists of the following steps:

\begin{enumerate}

\item download and install \gls{SSGet}

\item install required packages for \gls{Python}

\item download test reporter for test coverage report

\item run pytest-cov and create a file with the report

\item upload report to \gls{CodeClimate}

\end{enumerate}

\gls{Travis} will also send a report to the pull request on \gls{GitHub} to show if the build and tests were successful.
This helped to make sure that only code can be merged to the master, that doesn't brake existing tests.

\subsection{Code Checking}
Besides the continuous integration, we also integrated \gls{CodeClimate}.
\gls{CodeClimate} is a code checking tool that looks at the code and uses some metrics to decide how readable and complex the code is.
This tool is triggered when someone creates a pull request.
It then will look at all the code that differs from the master branch and creates a report about all the problematic code passages that where added.
We also added the \gls{PEP8} plugin to verify that our code is also \gls{PEP8} conform.
The \gls{CodeClimate} check was optional for a pull request, but we still tried to keep this test passing as well.
We kept it optional, because for some code passages, like the \gls{C++} files, we didn't quite have the time to clean up this code.
It still helped a lot to keep our code lean and readable.
Thanks to the \gls{Travis} test report, \gls{CodeClimate} also shows the current test coverage on each pull request together with its difference to the master branch.
When visiting the \gls{CodeClimate} website, you can also get a little summary of the code base of the master branch.



\newpage

\begin{sidewaysfigure}[ht]
    \includegraphics[width=\textwidth, height= \textheight, keepaspectratio]{../Big_classdiagram/Big_classdiagram.pdf}
    \caption{Big class diagram after design changes}
    \label{fig:PropProf}
\end{sidewaysfigure}


\newpage
\section{Glossary}
%\glspl{collector}, labeling modle, neural network, classifier, default settings  \glspl{Dateiformat}

% % Automatisch generiertes Glossar (Latex zwei mal ausführen um Glossar anzuzeigen)
%
%\glsaddall % das sorgt dafür, dass alles Glossareinträge gedruckt werden, nicht nur die verwendeten. Das sollte nicht nötig sein!
\printnoidxglossaries

\end{document}

